<!doctype html>
<html lang="en">
	<head>
    <title>IoTcraft</title>
		<meta charset="UTF-8" />
    <meta name="description" content="Connecting the virtual world with the physical." />
		<meta name="viewport" content="width=device-width, initial-scale=1.0" />
		<link rel="icon" type="image/x-icon" href="/favicon.ico" />
    <link rel="preconnect" href="https://fonts.googleapis.com" />
    <link rel="preconnect" href="https://fonts.gstatic.com" crossorigin />
    <link rel="preload" as="style" href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap" />
    <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap" media="print" onload="this.media='all'" />
    <noscript>
      <link rel="stylesheet" href="https://fonts.googleapis.com/css2?family=Montserrat:ital,wght@0,100..900;1,100..900&display=swap" />
    </noscript>
	</head>
  <body class="bg-[--background] md:px-48 lg:px-20 px-9">
		<slot />
	</body>
</html>
<style is:global>
  :root {
    --background: #101010;
    --sec: #0561ad;
    --white: #dfdfdf;
    --white-icon: #f3f3f398;
    --white-icon-tr: #f3f3f310;
  }
  * {
    font-family:
      "montserrat",
      -apple-system,
      system-ui,
      sans-serif;
    box-sizing: border-box;
    padding: 0;
    margin: 0;
  }
  *::selection {
    background-color: var(--sec);
    color: var(--background);
  }
  ::-webkit-scrollbar {
    width: 15px;
  }
  ::-webkit-scrollbar-track {
    background: var(--container);
    border-radius: 30px;
  }
  ::-webkit-scrollbar-thumb {
    background: var(--background);
    border-radius: 10px;
  }
  ::-webkit-scrollbar-thumb:hover {
    background: var(--pink);
  }
  * {
    scrollbar-width: thin;
    scrollbar-color: var(--line) var(--container);
  }
  .shiny-sec {
    background: linear-gradient(135deg, var(--sec) 25%, #eee5ff 50%, var(--sec) 75%);
    background-size: 400% 100%;
    -webkit-background-clip: text;
    background-clip: text;
    color: transparent;
    animation: shine 3s linear infinite;
  }
  @keyframes shine {
    0% {
      background-position: 100% 50%;
    }
    30%,
    70% {
      background-position: 0% 50%;
    }
  }
  .rotate {
    transform: rotateY(180deg);
  }
</style>
<script>
import mqtt from "mqtt"
import {
  DrawingUtils,
  FilesetResolver,
  GestureRecognizer
} from "https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3";

const camera = window.document.getElementById("camera");
const output = window.document.getElementById("output");
const canvas = window.document.getElementById("canvas");
const startButton = window.document.getElementById("startButton");
const drawingCanvas = canvas.getContext("2d");
const parameters = new URLSearchParams(window.location.search);
const url = parameters.get("url")
const port = parameters.get("port")
const topic = parameters.get("topic")
const recognizer = await GestureRecognizer.createFromOptions(await FilesetResolver.forVisionTasks("https://cdn.jsdelivr.net/npm/@mediapipe/tasks-vision@0.10.3/wasm"), {
  baseOptions: {
    modelAssetPath:
      "https://storage.googleapis.com/mediapipe-models/gesture_recognizer/gesture_recognizer/float16/1/gesture_recognizer.task",
    delegate: "GPU"
  },
  runningMode: "VIDEO",
  numHands: 10
});
let cameraStatus;
let resultsCache;
let lastTime;
let lastKeybind;
let x = 0;
let y = 0;
let lastX = 0;
let lastY = 0;
let client;
if (url !== null && port !== null && topic !== null) {
  client = mqtt.connect("wss://" + url + ":" + port + "/mqtt", {
    clean: true,
    connectTimeout: 4000,
    clientId: crypto.randomUUID(),
    username: "",
    password: "",
  })
  client.subscribe(topic)
  const topicX = topic + "_x"
  client.subscribe(topicX)
  const topicY = topic + "_y"
  client.subscribe(topicY)
  window.setInterval(sendLocation, 1000);
  window.setInterval(sendGesture, 1000);
}
startButton.addEventListener("click", enableWebcam);

async function enableWebcam() {
  if (cameraStatus === true) {
    cameraStatus = false;
    startButton.innerText = "UNPAUSE VISIONARY GESTURE RECOGNITION";
  } else {
    cameraStatus = true;
    startButton.innerText = "PAUSE VISIONARY GESTURE RECOGNITION";
  }
  window.navigator.mediaDevices.getUserMedia({video: true}).then(function (stream) {
    camera.srcObject = stream;
    camera.addEventListener("loadeddata", predictWebcam);
  });
}

function addKeybind() {
  const table = document.getElementById("keybinds");
  const row = table.rows[1];
  const clone = row.cloneNode(true);
  table.appendChild(clone);
}

function removeKeybind() {
  const table = document.getElementById("keybinds");
  if (table.rows.length > 2) {
    table.deleteRow(table.rows.length - 1);
  }
}

async function predictWebcam() {
  if (camera.currentTime !== lastTime) {
    lastTime = camera.currentTime;
    resultsCache = recognizer.recognizeForVideo(camera, Date.now());
  }
  drawingCanvas.save();
  drawingCanvas.clearRect(0, 0, canvas.width, canvas.height);
  // draw hand landmarks
  const landmarksResult = resultsCache.landmarks;
  if (landmarksResult.length > 0) {
    const utils = new DrawingUtils(drawingCanvas);
    for (const landmarks of landmarksResult) {
      utils.drawConnectors(landmarks, GestureRecognizer.HAND_CONNECTIONS, {color: "#646464", lineWidth: 10});
      utils.drawLandmarks(landmarks, {color: "#ffffff", lineWidth: 4});
      x = landmarks[8].x;
      y = landmarks[8].y;
    }
  }
  drawingCanvas.restore();
  // display output
  const gestureResult = resultsCache.gestures;
  if (gestureResult.length > 0) {
    // hands
    let handBuilder = []
    for (const handedness of resultsCache.handednesses) {
      handBuilder.push(oppositeHand(handedness[0].displayName));
    }
    let hands = handBuilder.join(", ");
    // gestures
    let gestureBuilder = []
    let confidenceBuilder = []
    for (const gesture of gestureResult) {
      const currentGesture = gesture[0];
      const name = currentGesture.categoryName;
      gestureBuilder.push(name);
      confidenceBuilder.push((currentGesture.score * 100.0).toFixed(2));
    }
    let gestures = gestureBuilder.join(", ");
    let confidences = confidenceBuilder.join(", ");
    output.innerText = "Hands: " + hands + "\nGestures: " + gestures + "\n Confidences: " + confidences;
  }
  if (cameraStatus === true) {
    window.requestAnimationFrame(predictWebcam);
  }
}

async function sendLocation() {
  if (x !== lastX) {
    client.publish(topicX, x.toString())
    lastX = x;
  }
  if (y !== lastY) {
    client.publish(topicY, y.toString())
    lastY = y;
  }
}

async function sendGesture() {
  if (resultsCache === undefined) {
    return;
  }
  if (resultsCache.handednesses.length < 2) {
    return;
  }
  // organize hand data
  const firstHand = oppositeHand(resultsCache.handednesses[0][0].displayName);
  const secondHand = oppositeHand(resultsCache.handednesses[1][0].displayName);
  let rightHand = 0;
  let leftHand = 0;
  if (firstHand === "Right" && secondHand === "Left") {
    leftHand = 1;
  } else if (firstHand === "Left" && secondHand === "Right") {
    rightHand = 1;
  } else {
    return;
  }
  // get gestures
  const leftGesture = resultsCache.gestures[leftHand][0].categoryName;
  const rightGesture = resultsCache.gestures[rightHand][0].categoryName;
  const rows = document.getElementById("keybinds").rows;
  // get requirements
  for (let i = 1; i < rows.length; i++) {
    const row = rows[i];
    const leftRequirement = row.cells[0].getElementsByTagName("md-outlined-select")[0].value;
    const rightRequirement = row.cells[1].getElementsByTagName("md-outlined-select")[0].value;
    const keybind = row.cells[2].getElementsByTagName("md-outlined-text-field")[0].value;
    // send gesture
    if (keybind === lastKeybind) {
      continue;
    }
    if (leftGesture === leftRequirement && rightGesture === rightRequirement) {
      client.publish(topic, keybind)
      lastKeybind = keybind;
      console.log("Sent gesture: " + keybind);
    }
  }
}

function oppositeHand(hand) {
  return hand === "Left" ? "Right" : "Left";
}

</script>
